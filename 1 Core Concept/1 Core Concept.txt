CLUSTER ARCHITECTURE

the purpose of kubernetes is to host your application in a container manner for easy automation and deploy many applications.
cargo ships are containers carriers called worker nodes. the control ship is the master node
the master node uses the control node components

ETCD==== The informations about this containers are stored in ETCD. this is a database that stores data in key-value manner.
kube scheduler === identifies the right node to place a container on.
node controllers === handles node
replication controller === ensures the numbers of containers are running
kubeapi server == manages the kubernetes system
kubelet === is the captain of the ship. and monitors status of nodes
kube proxy ==== ensures communications happens between nodes. webserver connecting to appserver.


=========================================================

DOCKER VS CONTAINERD

DOCKER uses docker command
CONTAINERD uses crictl command

=========================================

ETCD (port 2379)
key-value database key-value database stores data individually instead of the traditional database tables that combines all informations. 

ETCD - Commands
ETCDCTL is the CLI tool used to interact with ETCD.

ETCDCTL can interact with ETCD Server using 2 API versions - Version 2 and Version 3.  By default its set to use Version 2.
 Each version has different sets of commands.

For example ETCDCTL version 2 supports the following commands:

etcdctl backup
etcdctl cluster-health
etcdctl mk
etcdctl mkdir
etcdctl set


Whereas the commands are different in version 3

etcdctl snapshot save 
etcdctl endpoint health
etcdctl get
etcdctl put

To set the right version of API set the environment variable ETCDCTL_API command

export ETCDCTL_API=3



When API version is not set, it is assumed to be set to version 2. And version 3 commands listed above don't work. When API version is set to version 3,
version 2 commands listed above don't work.



Apart from that, you must also specify path to certificate files so that ETCDCTL can authenticate to the ETCD API Server. 
The certificate files are available in the etcd-master at the following path. We discuss more about certificates in the security section of this course. 
So don't worry if this looks complex:

--cacert /etc/kubernetes/pki/etcd/ca.crt     
--cert /etc/kubernetes/pki/etcd/server.crt     
--key /etc/kubernetes/pki/etcd/server.key


So for the commands I showed in the previous video to work you must specify the ETCDCTL API version and path to certificate files. 
Below is the final form:



kubectl exec etcd-master -n kube-system -- sh -c "ETCDCTL_API=3 etcdctl get / --prefix --keys-only --limit=10 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt  --key /etc/kubernetes/pki/etcd/server.key"


=================================================================================================

KUBE-API SERVER
This is the only tool that interacts with the ETCD directly.
It manages the chnages in the application/container image
Authenticate users, validate requests, retrieves data, update ETCD, scheduler and kublet uses kube-api server to perform update in the cluster.

installing kube-api server
wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubeapi-server

========================================================

KUBE CONTROLLER MANAGER
Watch status, remediate situation, node monitor period = 5secs node moniotor grace period = 40s, pod eviction timeout = 5mins.

installing kubernetes contoller manager
wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-controller-manager

=========================================================

KUBE SCHEDULER
The scheduler decides which pod goes on which node. pls not it doesnt create the pod, it is the job of the kubelet to create the pod.
it only decides the fate of the pod on which node it should be placed.

wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler

================================================

KUBELET
Kubelet is like a captain on the ship. they load and unload the pod from the master to the nodes.
kubelet monitors and report to the controller. kubeadm does not install kubelet. you must manually install kubelet.

wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet

pls note the command to grep:
ps -aux | grep kubelet

#replace kubelet with other resources/components
=====================================================================

KUBE PROXY
Ensures communication between nodes. this is a process that runs on each node in the kubernetes cluster and connection is possible with the pod network.
its job is to look for node and channel traffic to the node.

wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy

=============================================================

RECAP POD
PODS are kubernetes objects that houses docker containers. containers are kept inside the pod.
a pod is a single instance of an object. a pod is the smallest thing that can be created in kubernetes
a single pod can have multiple container
the two containers in a pod can communicate with each other since they share the same network space.

creating a pod

kubectl run ngnix --image nginx  #this creates a pod automatically
kubectl get pod  # to see your created pods


==================================================================

YAML IN KUBERNETES. (AKMS = apiVersion, kind, metadata, spec)

A kubernetes yaml file contains the follow parameters which are the four top level properties in kubernetes.

apiVersion
kind
metadata
spec.


apiVersion: v1  #depends on the kind of objects you are creating
kind: Pod   # it can be Service, ReplicaSet, Deployment.
metadata:  # this involves data about the object. the name, labels and others
  name: myapp-pod
  labels:
    app: myapp
    type: front-end
spec:
  containers:    # =======list/array
  - name: nginx-containeter   # the dash (-) before the name indicates this is the first item on the list. 
    image: nginx

to create a pod, paste this in the file created as pod.yaml
then, run the command

kubectl create -f pod-definition.yaml
kubectl get pod  #to see details about the pod 

from spec: , you can add a second container element.

apiVersion: v1  
kind: Pod   
metadata:  
  name: myapp-pod
  labels:
    app: myapp
    type: front-end
spec:
  containers:    
  - name: nginx-container   
    image: nginx
  - name: busybox-container
  - image: busybox


to create, paste the above in pod.yaml file and run the command:

kubectl apply -f pod.yaml
===========================================================

Accessing the Labs
All hands-on labs are hosted on KodeKloud. Use this link to register for the labs associated with this course. 
Please make sure to use the same name as your profile in Udemy. That's how we know you are our Udemy student.


It's FREE. You don't have to make any additional payment.

It's not required to complete this course on Udemy

To participate, you'll be registering to a new platform - KodeKloud, separate from Udemy

You'll be added to a mailing list after registration. You may choose to opt out of it.



Link: https://uklabs.kodekloud.com/courses/labs-certified-kubernetes-administrator-with-practice-tests/

Apply the coupon code udemystudent151113



=================================================================


test question pod
creating a pod = kubectl run nginx --image=nginx
creating and output in yaml command = kubectl run nginx --image=nginx --dry-run=client -o yaml
breaking this into a file = kubectl run nginx --image=nginx --dry-run=client -o yaml > redis.yaml
getting details of the image name of a pod = kubectl describe pod pod-name  #get image details in the output


============================================

REPPLICASET/REPLICATION CONTROLLER

This ensures that the desired number of pods are running. if our application crashes, users will not be able to access our application, replicaset ensures 
more pods are created when a pod goes down. works like ec2 autoscaling. it also does load balancing on the pod.

FOR REPLICATION CONTROLLER 


apiVersion: v1
kind: ReplicationController
metadata:
  name: my-app
  label:
    app: my-app
    tier: front-end
spec:
  template:
    metadata:
      label:
        app: nginx
        tier: front-end
    spec:
      containers:
      - name: nginx-container
        image: nginx
  replicas: 3

kubectl create -f name.yam;l
kubectl get replicationcontroller
kubectl get pod.

 
FOR REPLICASET

on of the major diffrence between replcatset and replication controller is selector. the selector helps you to add mopre pods that exist before the rep[licaset was created
replicaset use the apiVersion: app/v1 AND kind: ReplicaSet

apiVersion: app/v1
kind: ReplicaSet
metadata:
  name: my-app
  labels:
    app: my-app
    tier: front-end
spec:
  template:
    metadata:
      label:
        app:nginx
        tier: front-end
    spec:
      containers:
      - name: nginx-container
        image: nginx
  replicaset:3
  selector:
    matchlabels:
      tier: front-end

kubectl create -f name.yaml
kubectl get replicaset

Template definition: this is required incase the pod fails in future. the replicaset can pick the matchlabels and use it to create a new pod as desired.

HOW WE NOW EDIT THE NUMBER OF REPLICA. 

1ST= edit the yaml fine for the replicaset and edit the replicaset option to the new desired number. e.g 6
the run the command: kubectl replace -f name.yaml

2ND: run the command to update automatically: kubectl scale --replicas=6 -f name.yaml

3RD= kubectl scale --replicas=6 replicaset my-app    (my-app is the name of the pod on the metadata syntax.)

commands
kubectl create -f name.yaml
kubectl describe replicaset
kubectl delete replicaset name.yaml or kubectl delete replicaset my-app = also deletes underlying pods.
kubectl replace -f name.yaml
kubectl scale --replicas=6 -f name.yaml



==================================================

DEPLOYMENT

Rolling Update : update your application one after the other so that it does not affect your application performance.

deployments provides the capability to update your instances using rolling update to make changes.

deployment yaml file is similar to that of replicaset except for the kind paramaters which you chnage to Deployment

in the deployment yaml file, you can also create a replicate inside the file.

run the kubectl create -f deployment.yaml
kubectl get deployments = to see your deployments 
kubectl get replicaset = to see the  created replicaset
kubectl get all === to see all the created objects.


apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
    tier: front-end
spec:
  template:
    metadata:
      label:
        app:nginx
        tier: front-end
    spec:
      containers:
      - name: nginx-container
        image: nginx
  replicaset:3
  selector:
    matchlabels:
      tier: front-end


========================================================================

Certification Tip!
Here's a tip!

As you might have seen already, it is a bit difficult to create and edit YAML files. Especially in the CLI. During the exam, you might find it difficult to copy 
and paste YAML files from browser to terminal. Using the kubectl run command can help in generating a YAML template.
And sometimes, you can even get away with just the kubectl run command without having to create a YAML file at all.
For example, if you were asked to create a pod or deployment with specific name and image you can simply run the kubectl run command.

Use the below set of commands and try the previous practice tests again, but this time try to use the below commands instead of YAML files.
Try to use these as much as you can going forward in all exercises

Reference (Bookmark this page for exam. It will be very handy):

https://kubernetes.io/docs/reference/kubectl/conventions/

Create an NGINX Pod

kubectl run nginx --image=nginx

Generate POD Manifest YAML file (-o yaml). Don't create it(--dry-run)

kubectl run nginx --image=nginx --dry-run=client -o yaml

Create a deployment

kubectl create deployment --image=nginx nginx

Generate Deployment YAML file (-o yaml). Don't create it(--dry-run)

kubectl create deployment --image=nginx nginx --dry-run=client -o yaml

Generate Deployment YAML file (-o yaml). Don’t create it(–dry-run) and save it to a file.

kubectl create deployment --image=nginx nginx --dry-run=client -o yaml > nginx-deployment.yaml         

Make necessary changes to the file (for example, adding more replicas) and then create the deployment.

kubectl create -f nginx-deployment.yaml



OR

In k8s version 1.19+, we can specify the --replicas option to create a deployment with 4 replicas.

kubectl create deployment --image=nginx nginx --replicas=4 --dry-run=client -o yaml > nginx-deployment.yaml


=========================================================================================================


KUBERNETES SERVICES

Enables communication within and outside of the application.
it helps us connect applications together.
enables connectivity between pods
helps in establishing connectivity to external data source
target port = port for the nodes
port = port on the service\
nodeport = port on the node where external services connects to the node


apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  type:NodePort
  ports:
    targetPort: 80
    port: 80
    nodePort: 30008
  selector:                                  
    app: my-app
    tier: front-end

note, this will be added to the deplyment file.

in the above script, the selectopr details is curled from the label in the pod details either in the deployment or a seperate pod file.
kubectl create -f service.yaml
kubectl get service
curl https://localhost:30008.

=============================================================================

CLUSTER IP

this ensure that the pod retains their original IP when when  they are restored after pod is destroyed. it ensures uniform communcication between pods

===========================================

LOAD BALANCER
 used to balance te load coming through the node.
ensures traffic is evenly distributed accross nodes.

==================================================

NAMESPACE

Pods, services and deployments are all kept inside the namesapce. the namespace is like a house which governs all kubernetes objects
kube-system and kube-public are default namespace created by kubernetes.
all resources made available to users are created in the default namespaces
if your environment is small, you can use default namespace.
objects in the same namespace can talk to each other using their first name
objects in different namespace must reference the namespace of each other.
example:

mysql can talk to a service named db-service in the same nsmaespace in this way; mysql.connect("db-service")  ==== db-service is the dns name
they cannot communicate in different namespace like this mysql.connect("db-service.dev.svc.cluster.local") ==== db-service.dev.svc.cluster.local is the dns name
cluster.lcoal = default domain name of the kubernetes cluster
svc= sub domain for service
dev = namespace
db-service = name of the service

kubectl create pod --namespace=dev   = to ensure it doesnt create in default.

to ensure your pod uses the dev namespace at all times, add namespace to the kubernetes yaml file under metadata block in the pod,

apiVersion: v1
kind: Pod
metadata:
  namespace: dev
  name: myapp-pod
  labels:
    app: myapp
    type: front-end
spec:
  containers:
  - name: nginx-containeter
    image: nginx

now create a namespace


apiVersion:v1
kind: NameSpace
metadata:
  name:dev


kubectl create -f namesapce-dev.yaml

or you can automate the creation like this below:
kubectl create namespace dev     === it will create a namespace called dev.

to limit a resource in a namespace. create a ResourceQuota

apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota
  namespace: dev
spec:
  hard:
    pods: "10"
    requests.cpu: "4"
    requests.memory: 5Gi
    limits.cpu: "10"
    limit.memory: 10Gi

run the script: 
kubectl create -f compute-quota.yaml

kubectl get pods --all-namespaces === list all the pods in the namespaces.

OR USE

kubectl get pods -A


==========================================================================

IMPERATIVE AND DECLARATIVE APPROACH IN KUBERNETES.

In imperative approach, you give a step by step instruction on the approach to get to the destination.
In declarative, you just specify the and declare the destination. the system finds the path to the destination. you dont need to provide a step by step instruction.

imperative

create objects
kubectl run --image=nginx nginx
kubectl create deployment --image=nginx nginx
kubectl expose deployment nginx --port 80

update objects
kubectl edit deployment nginx
kubectl scale deployment nginx --replicas=5
kubectl set image deployment nginx --image=nginx:1.18



kubectl create -f nginx.yaml
kubectl replace -f nginx.yaml
kubectl delete -f nginx.yaml

declarative

in declarative, we use the kubectl apply -f nginx.yaml command.
the comnmand looks at what configuration needs to be done to the system and make appropriate changes.
manifest file helps us to design what we want the object to look like

kubectl edit deployment nginx.yaml 
after editing, use the replace command to update any edit done on the manifest file
kubectl replace -f nginx.yaml
this is still imperative,

to use declarative, use the kubectl apply -f nginx.yaml to apply the changes made

kubectl apply command is intelligent enough to create an object if it doesnt alreday exist and update already existing object.

EXAM TIPS: if the exam is asking you to create a pod or deployment using a given image, then you can use the imperative command to save time.
so it is important to practise the imperative commands as much as possible
if you need to a edit a manifest file, use the kubectl edit command.

if it involves many pods and objects, use the kubectl apply command to update or create all objects.



=========================================================================================


Certification Tips - Imperative Commands with Kubectl
While you would be working mostly the declarative way - using definition files, imperative commands can help in getting one time tasks done quickly,
as well as generate a definition template easily. This would help save considerable amount of time during your exams.

Before we begin, familiarize with the two options that can come in handy while working with the below commands:

--dry-run: By default as soon as the command is run, the resource will be created. If you simply want to test your command , 
use the --dry-run=client option. This will not create the resource, instead, tell you whether the resource can be created and if your command is right.

-o yaml: This will output the resource definition in YAML format on screen.



Use the above two in combination to generate a resource definition file quickly, that you can then modify and create resources as required,
instead of creating the files from scratch.



POD
Create an NGINX Pod

kubectl run nginx --image=nginx



Generate POD Manifest YAML file (-o yaml). Don't create it(--dry-run)

kubectl run nginx --image=nginx --dry-run=client -o yaml



Deployment
Create a deployment

kubectl create deployment --image=nginx nginx



Generate Deployment YAML file (-o yaml). Don't create it(--dry-run)

kubectl create deployment --image=nginx nginx --dry-run=client -o yaml



Generate Deployment with 4 Replicas

kubectl create deployment nginx --image=nginx --replicas=4



You can also scale a deployment using the kubectl scale command.

kubectl scale deployment nginx --replicas=4

Another way to do this is to save the YAML definition to a file and modify

kubectl create deployment nginx --image=nginx --dry-run=client -o yaml > nginx-deployment.yaml



You can then update the YAML file with the replicas or any other field before creating the deployment.



Service
Create a Service named redis-service of type ClusterIP to expose pod redis on port 6379

kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml

(This will automatically use the pod's labels as selectors)

Or

kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml (This will not use the pods labels as selectors, 
instead it will assume selectors as app=redis. You cannot pass in selectors as an option. So it does not work very well if your pod has a different label set.
So generate the file and modify the selectors before creating the service)



Create a Service named nginx of type NodePort to expose pod nginx's port 80 on port 30080 on the nodes:

kubectl expose pod nginx --type=NodePort --port=80 --name=nginx-service --dry-run=client -o yaml

(This will automatically use the pod's labels as selectors, but you cannot specify the node port. You have to generate a definition file 
and then add the node port in manually before creating the service with the pod.)

Or

kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml

(This will not use the pods labels as selectors)

Both the above commands have their own challenges. While one of it cannot accept a selector the other cannot accept a node port. 
I would recommend going with the kubectl expose command. If you need to specify a node port, generate a definition file using the same command and manually
input the nodeport before creating the service

Reference:
https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands

https://kubernetes.io/docs/reference/kubectl/conventions/



============================================================================


























 